{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aAp0uJ2VQ8sZ",
    "outputId": "1e3efe33-5564-447d-a6ac-c9ef33785d71"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.25.0\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Denis\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Denis\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import string\n",
    "impor\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, SimpleRNN, LSTM, GRU, Dense\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing import sequence\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, roc_curve, auc\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "plt.style.use('dark_background')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RsWZBu_otF_i"
   },
   "outputs": [],
   "source": [
    "# Загружаем стоп-слова из библиотеки NLTK\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "DcO8SxidRCnN",
    "outputId": "ed804bc3-6b06-457c-9671-4fb0264a5764"
   },
   "outputs": [],
   "source": [
    "# Считываем датасет\n",
    "df = pd.read_csv(r'FakeNewsNet.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mSyRP83lS5FY",
    "outputId": "35365e2d-23a9-4373-dd9c-16d20492d89f"
   },
   "outputs": [],
   "source": [
    "# Проверяем на наличие null-значений\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0xFLiMVMZQvh"
   },
   "outputs": [],
   "source": [
    "# Удаляем null-значения, если есть\n",
    "# df_cleaned = df.dropna()\n",
    "# df_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 410
    },
    "id": "TWzfxfumZyLO",
    "outputId": "1d8bcba9-7ac1-4a4e-be9b-77b204894578"
   },
   "outputs": [],
   "source": [
    "# Количество элементов каждого класса\n",
    "class_counts = df['sentiment'].value_counts()\n",
    "\n",
    "# Визуализация графика баланса классов\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.countplot(x='sentiment', data=df, hue='sentiment', palette='Set2') #, legend=False)\n",
    "plt.title('Баланс классов')\n",
    "plt.xlabel('Классы')\n",
    "plt.ylabel('Количество элементов')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GKUKL0RptMIr"
   },
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    # Удаляем знаки препинания\n",
    "    text = text.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "\n",
    "    # Приводим к нижнему регистру\n",
    "    text = text.lower()\n",
    "\n",
    "    # Токенизация текста\n",
    "    tokens = word_tokenize(text)\n",
    "\n",
    "    # Удаляем стоп-слова\n",
    "    tokens = [word for word in tokens if word.lower() not in stop_words]\n",
    "\n",
    "    # Удаляем числа и другие символы\n",
    "    tokens = [word for word in tokens if word.isalpha()]\n",
    "\n",
    "    # Склеиваем токены обратно в строку\n",
    "    preprocessed_text = ' '.join(tokens)\n",
    "\n",
    "    return preprocessed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l03aAOZ9tPuo"
   },
   "outputs": [],
   "source": [
    "def preprocess_dataframe(dataframe, text_column):\n",
    "    # Применяем preprocess_text ко всем значениям в указанной колонке\n",
    "    dataframe[text_column] = dataframe[text_column].apply(preprocess_text)\n",
    "\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "yY_ryiCotTnQ",
    "outputId": "c2b97dce-9d39-4b11-8f3d-58b6cecb971d"
   },
   "outputs": [],
   "source": [
    "preprocess_dataframe(df, 'review')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_GjUZTdh6uMP"
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(df['review'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pxSJxH06lhQE"
   },
   "outputs": [],
   "source": [
    "# Получение словаря\n",
    "word_index = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_cQO0dL36-dp",
    "outputId": "a84208fd-adfb-43e1-89e5-788d86fec58c"
   },
   "outputs": [],
   "source": [
    "sequences = tokenizer.texts_to_sequences(df['review'].tolist())\n",
    "data = sequence.pad_sequences(sequences)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Rgo-39l0upeN"
   },
   "outputs": [],
   "source": [
    "# Кодируем категориальный признак\n",
    "category_mapping = {'positive': 1, 'negative': 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y9h9bkqUuuQb"
   },
   "outputs": [],
   "source": [
    "df['label'] = df['sentiment'].replace(category_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UKDaxPH483Oi"
   },
   "outputs": [],
   "source": [
    "# Разделение на трейн и тест\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, df['label'], test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vQNVLnBrO1Fe"
   },
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vdMnRJ57peIT"
   },
   "outputs": [],
   "source": [
    "vocab_size = len(tokenizer.word_index) + 1  # добавляем 1, так как индексы начинаются с 1\n",
    "max_length = max(len(seq) for seq in sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j1ql8E7N06U9",
    "outputId": "ef16bb84-fc79-4c0a-9634-655d57f9218f"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(input_dim=vocab_size, output_dim=128, input_length=max_length),\n",
    "    tf.keras.layers.LSTM(units=64),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')  # для бинарной классификации\n",
    "])\n",
    "\n",
    "# Используем early_stop, который прекращает обучение, когда validation loss больше не улучшается\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=2, restore_best_weights=True)\n",
    "\n",
    "# Компиляция модели\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Обучение модели\n",
    "history = model.fit(X_train, y_train, epochs=10, validation_split=0.2, batch_size=30, shuffle=True, callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 797
    },
    "id": "7IUwwqrfssNx",
    "outputId": "7d39994f-fd1f-4a30-a635-9ad70c65f5a0"
   },
   "outputs": [],
   "source": [
    "history_dict = history.history\n",
    "\n",
    "acc = history_dict['accuracy']\n",
    "val_acc = history_dict['val_accuracy']\n",
    "loss = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "epochs = history.epoch\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(epochs, loss, 'r', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss', size=10)\n",
    "plt.xlabel('Epochs', size=10)\n",
    "plt.ylabel('Loss', size=10)\n",
    "plt.legend(prop={'size': 10})\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(epochs, acc, 'g', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy', size=10)\n",
    "plt.xlabel('Epochs', size=10)\n",
    "plt.ylabel('Accuracy', size=10)\n",
    "plt.legend(prop={'size': 10})\n",
    "plt.ylim((0.5,1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 541
    },
    "id": "0SUsksaD8xYx",
    "outputId": "b5dce681-5269-4955-da5f-3c0cc6add455"
   },
   "outputs": [],
   "source": [
    "# Получаем предсказания\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Округляем вероятности до 0 или 1\n",
    "y_pred_binary = np.round(y_pred)\n",
    "\n",
    "# Оцениваем производительность модели\n",
    "accuracy = accuracy_score(y_test, y_pred_binary)\n",
    "f1 = f1_score(y_test, y_pred_binary)\n",
    "roc_auc = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "# Выводим результаты\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"ROC AUC Score:\", roc_auc)\n",
    "\n",
    "# Строим ROC-кривую\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
